{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Section 4: Random Forest Classifier for High-Income Prediction\n",
    "\n",
    "This notebook implements a Random Forest classifier to predict high-income individuals (>=$50K annual income) using Census Bureau data. It addresses key findings from EDA:\n",
    "- 2.3x sample weight bias (high-income individuals underrepresented)\n",
    "- Education x occupation interaction (education alone fails to predict income)\n",
    "- Severe class imbalance (6.2% high-income vs 93.8% low-income)\n",
    "\n",
    "The model uses sample weights during training and class balancing to handle these challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "print('=' * 80)\n",
    "print('INCOME CLASSIFICATION MODEL - RANDOM FOREST')\n",
    "print('=' * 80)\n",
    "print('\\nLibraries imported successfully\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_column_names(columns_file):\n",
    "    \"\"\"Load column names from header file.\"\"\"\n",
    "    with open(columns_file, 'r') as f:\n",
    "        columns = [line.strip().rstrip(':').strip() for line in f if line.strip()]\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SECTION 1: Loading Data')\n",
    "print('-' * 80)\n",
    "\n",
    "# Load column names\n",
    "column_names = load_column_names('../data/census-bureau.columns')\n",
    "print(f'Loaded {len(column_names)} column names')\n",
    "\n",
    "# Load data\n",
    "data_file = '../data/census-bureau.data'\n",
    "df = pd.read_csv(data_file, header=None, names=column_names, skipinitialspace=True)\n",
    "print(f'Data loaded: {df.shape[0]:,} rows x {df.shape[1]} columns')\n",
    "\n",
    "# Create binary target variable\n",
    "label_col = 'label'\n",
    "df['income_binary'] = (df[label_col].str.strip() == '50000+.').astype(int)\n",
    "print(f'Target variable created: income_binary')\n",
    "print(f'  Class distribution: {df[\"income_binary\"].value_counts().to_dict()}')\n",
    "print(f'  High-income rate: {df[\"income_binary\"].mean()*100:.2f}%')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SECTION 2: Feature Engineering')\n",
    "print('-' * 80)\n",
    "\n",
    "# Define column names\n",
    "age_col = 'age'\n",
    "edu_col = 'education'\n",
    "occ_col = 'major occupation code'\n",
    "weeks_col = 'weeks worked in year'\n",
    "marital_col = 'marital stat'\n",
    "workclass_col = 'class of worker'\n",
    "weight_col = 'weight'\n",
    "\n",
    "# Select feature columns\n",
    "feature_cols = [age_col, edu_col, occ_col, weeks_col, marital_col, workclass_col]\n",
    "print('Selected features:')\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f'  {i}. {col}')\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df['income_binary'].copy()\n",
    "sample_weights = df[weight_col].copy()\n",
    "\n",
    "print(f'\\nFeature matrix: {X.shape}')\n",
    "print(f'Target vector: {y.shape}')\n",
    "print(f'Sample weights: {sample_weights.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_counts = X.isnull().sum()\n",
    "print('Missing values check:')\n",
    "if missing_counts.sum() == 0:\n",
    "    print('  No missing values detected')\n",
    "else:\n",
    "    print(missing_counts[missing_counts > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "categorical_cols = [edu_col, occ_col, marital_col, workclass_col]\n",
    "label_encoders = {}\n",
    "\n",
    "print('Encoding categorical features:')\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "    print(f'  {col}: {len(le.classes_)} unique categories')\n",
    "\n",
    "print('\\nFeature engineering complete\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SECTION 3: Train/Test Split')\n",
    "print('-' * 80)\n",
    "\n",
    "X_train, X_test, y_train, y_test, weights_train, weights_test = train_test_split(\n",
    "    X, y, sample_weights,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print('Train/test split results:')\n",
    "print(f'  Training set: {X_train.shape[0]:,} samples')\n",
    "print(f'  Test set: {X_test.shape[0]:,} samples')\n",
    "print(f'\\nClass distribution verification:')\n",
    "print(f'  Training high-income rate: {y_train.mean()*100:.2f}%')\n",
    "print(f'  Test high-income rate: {y_test.mean()*100:.2f}%')\n",
    "print('\\nData split complete\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SECTION 4: Model Training')\n",
    "print('-' * 80)\n",
    "\n",
    "print('Training Random Forest classifier...')\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=100,\n",
    "    min_samples_leaf=50,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train, sample_weight=weights_train)\n",
    "\n",
    "print('Model training complete')\n",
    "print(f'  Number of trees: {rf_model.n_estimators}')\n",
    "print(f'  Max depth: {rf_model.max_depth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "print('Generating predictions on test set...')\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print('Predictions generated')\n",
    "print(f'  Test set size: {len(y_test):,}')\n",
    "print(f'  Predicted high-income: {y_pred.sum():,} ({y_pred.mean()*100:.2f}%)')\n",
    "print(f'  Actual high-income: {y_test.sum():,} ({y_test.mean()*100:.2f}%)')\n",
    "print('\\nModel training and prediction complete\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SECTION 5: Model Evaluation')\n",
    "print('=' * 80)\n",
    "\n",
    "print('\\n1. CLASSIFICATION REPORT:')\n",
    "print('-' * 80)\n",
    "print(classification_report(y_test, y_pred,\n",
    "                          target_names=['Low Income (<$50K)', 'High Income (>=$50K)'],\n",
    "                          digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f'\\n2. ROC-AUC SCORE: {roc_auc:.4f}')\n",
    "print(f'   Strong discrimination ability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "print('\\n3. CONFUSION MATRIX:')\n",
    "print('-' * 80)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index=['Actual: Low Income', 'Actual: High Income'],\n",
    "                     columns=['Predicted: Low Income', 'Predicted: High Income'])\n",
    "print(cm_df)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f'\\nTrue Negatives: {tn:,}')\n",
    "print(f'False Positives: {fp:,}')\n",
    "print(f'False Negatives: {fn:,}')\n",
    "print(f'True Positives: {tp:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business metrics\n",
    "print('\\n4. BUSINESS METRICS:')\n",
    "print('-' * 80)\n",
    "\n",
    "recall_high_income = tp / (tp + fn)\n",
    "print(f'Market Coverage (Recall): {recall_high_income:.1%}')\n",
    "\n",
    "precision_high_income = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "print(f'Campaign Efficiency (Precision): {precision_high_income:.1%}')\n",
    "\n",
    "fpr_rate = fp / (fp + tn)\n",
    "print(f'False Positive Rate: {fpr_rate:.1%}')\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(f'Overall Accuracy: {accuracy:.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SECTION 6: Feature Importance Analysis')\n",
    "print('=' * 80)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print('\\nFeature Importance Rankings:')\n",
    "print('-' * 80)\n",
    "print(feature_importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SECTION 7: Generating Visualizations')\n",
    "print('-' * 80)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. Confusion Matrix Heatmap\n",
    "cm_normalized = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
    "            xticklabels=['Predicted: Low', 'Predicted: High'],\n",
    "            yticklabels=['Actual: Low', 'Actual: High'],\n",
    "            ax=axes[0], cbar_kws={'label': '% of Actual Class'})\n",
    "axes[0].set_title('Confusion Matrix\\n(Normalized by True Class)', fontweight='bold', fontsize=12)\n",
    "axes[0].set_ylabel('Actual Income', fontweight='bold')\n",
    "axes[0].set_xlabel('Predicted Income', fontweight='bold')\n",
    "\n",
    "# 2. ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "axes[1].plot(fpr, tpr, color='darkorange', lw=2, label=f'Random Forest (AUC = {roc_auc:.3f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier (AUC = 0.500)')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('False Positive Rate', fontweight='bold')\n",
    "axes[1].set_ylabel('True Positive Rate (Recall)', fontweight='bold')\n",
    "axes[1].set_title('ROC Curve\\nDiscrimination Ability', fontweight='bold', fontsize=12)\n",
    "axes[1].legend(loc='lower right')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# 3. Feature Importance\n",
    "sns.barplot(data=feature_importance, y='feature', x='importance', palette='viridis', orient='h', ax=axes[2])\n",
    "axes[2].set_title('Feature Importance\\n(Gini Importance)', fontweight='bold', fontsize=12)\n",
    "axes[2].set_xlabel('Importance Score', fontweight='bold')\n",
    "axes[2].set_ylabel('Feature', fontweight='bold')\n",
    "axes[2].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "print('Visualizations generated')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Business Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SECTION 8: Business Recommendations')\n",
    "print('=' * 80)\n",
    "\n",
    "print('''\n",
    "RECOMMENDED DEPLOYMENT APPROACH:\n",
    "\n",
    "Combine both models for optimal results:\n",
    "\n",
    "1. First pass: Segmentation (Rule-based model)\n",
    "   - Assign customers to segments\n",
    "   - Provides interpretability\n",
    "\n",
    "2. Second pass: Classification (Random Forest)\n",
    "   - Score customers using probability (0-100%)\n",
    "   - Provides precision for targeting\n",
    "\n",
    "3. Threshold tuning:\n",
    "   - Calibrate based on campaign cost\n",
    "   - Expensive campaign: Use 70-80% threshold\n",
    "   - Cheap campaign: Use 30-40% threshold\n",
    "\n",
    "LIMITATIONS:\n",
    "1. Data age: Census data from 1994-1995\n",
    "2. Threshold needs business cost analysis\n",
    "3. Feature drift monitoring needed\n",
    "4. Fairness audit required before deployment\n",
    "''')\n",
    "\n",
    "print('=' * 80)\n",
    "print('ANALYSIS COMPLETE')\n",
    "print('=' * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
